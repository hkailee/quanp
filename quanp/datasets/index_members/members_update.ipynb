{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding TFX\n",
      "dropping PCG\n",
      "adding ATO\n",
      "dropping NFX\n",
      "adding WAB\n",
      "dropping GT\n",
      "adding DOW\n",
      "dropping BHF\n",
      "adding CTVA\n",
      "dropping FLR\n",
      "adding BMS\n",
      "dropping MAT\n",
      "adding MKTX\n",
      "dropping LLL\n",
      "adding TMUS\n",
      "dropping RHT\n",
      "adding IEX\n",
      "adding LDOS\n",
      "dropping FL\n",
      "dropping APC\n",
      "adding CDW\n",
      "dropping TSS\n",
      "adding NVR\n",
      "dropping JEF\n",
      "adding LVS\n",
      "dropping NKTR\n",
      "adding NOW\n",
      "dropping CELG\n",
      "adding WRB\n",
      "dropping VIAB\n",
      "adding ODFL\n",
      "dropping STI\n",
      "adding ZBRA\n",
      "adding LYV\n",
      "adding STE\n",
      "dropping TRIP\n",
      "dropping AMG\n",
      "dropping MAC\n",
      "adding PAYC\n",
      "dropping WCG\n",
      "adding GDI\n",
      "dropping XEC\n",
      "adding CARR\n",
      "adding OTIS\n",
      "dropping RTN\n",
      "dropping M\n",
      "adding DXCM\n",
      "adding DPZ\n",
      "dropping AGN\n",
      "dropping CPRI\n",
      "adding WST\n",
      "dropping HP\n",
      "adding TYL\n",
      "adding TDY\n",
      "adding BIO\n",
      "dropping JWN\n",
      "dropping HOG\n",
      "dropping ADS\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sp500.csv')\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True )\n",
    "df.set_index('date', inplace=True, drop=True)\n",
    "\n",
    "df_mod = pd.read_csv('modification_20200802.csv')\n",
    "df_mod['date'] = pd.to_datetime(df_mod['date'])\n",
    "df_mod = df_mod.sort_values(by=['date'], ascending=True)\n",
    "df_mod.set_index('date', inplace=True, drop=True)\n",
    "\n",
    "\n",
    "df_dict = {}\n",
    "for item in df.index:\n",
    "    df_dict[item.strftime('%Y-%m-%d')] = df.at[item, 'tickers'].split(',')\n",
    "    \n",
    "last_date = df.index[-1:].strftime('%Y-%m-%d').values[0]\n",
    "df_mod.index = df_mod.index.strftime('%Y-%m-%d')\n",
    "\n",
    "for dt in df_mod.index.unique():\n",
    "    df_dict[dt] = df_dict[last_date].copy()\n",
    "    \n",
    "    try:\n",
    "        if df_mod.at[dt, 'ticker_add']:\n",
    "            tick = df_mod.at[dt, 'ticker_add']\n",
    "            df_dict[dt].append(tick)\n",
    "            print('adding', df_mod.at[dt, 'ticker_add'])\n",
    "            \n",
    "    except:\n",
    "        for tick in df_mod.at[dt, 'ticker_add']:\n",
    "            if tick is not np.nan:\n",
    "                df_dict[dt].append(tick)\n",
    "                print('adding', tick)\n",
    "                \n",
    "    try:\n",
    "        if df_mod.at[dt, 'ticker_drop']:\n",
    "            df_dict[dt].remove(df_mod.at[dt, 'ticker_drop'])\n",
    "            print('dropping', df_mod.at[dt, 'ticker_drop'])\n",
    "\n",
    "    except:\n",
    "        for tick in df_mod.at[dt, 'ticker_drop']:\n",
    "            if tick is not np.nan:\n",
    "                df_dict[dt].remove(tick)\n",
    "                print('dropping', tick)\n",
    "                \n",
    "    last_date = dt\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame(columns=['tickers'])\n",
    "\n",
    "for key in df_dict.keys():\n",
    "#     df_final.at[key, 'tickers'] = df_dict[key]\n",
    "    df_final.at[key, 'tickers'] = ','.join(df_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for date in df_final.index[-24:]:\n",
    "#     print(date)\n",
    "#     print(df_final.at[date, 'tickers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1996-01-02', '1996-01-03', '1996-01-04', '1996-01-10',\n",
       "               '1996-01-11', '1996-01-12', '1996-01-22', '1996-01-23',\n",
       "               '1996-01-24', '1996-01-30',\n",
       "               ...\n",
       "               '2019-12-05', '2019-12-09', '2019-12-23', '2020-01-28',\n",
       "               '2020-03-03', '2020-04-03', '2020-04-06', '2020-05-12',\n",
       "               '2020-05-22', '2020-06-22'],\n",
       "              dtype='datetime64[ns]', length=2618, freq=None)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df_final.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final.to_csv('sp500_20100801.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# drop any company that has value nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "csv_dir ='../../Data/daily/'\n",
    "\n",
    "# filter out downloaded tickers\n",
    "downloaded_tickers = os.listdir(csv_dir)\n",
    "print(len(downloaded_tickers))\n",
    "\n",
    "ls_csv_with_na = []\n",
    "for csv in downloaded_tickers:\n",
    "    df = pd.read_csv(csv_dir + csv, index_col=0)\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "#         df[col] = df[col].astype(int)\n",
    "#         df.to_csv(csv_dir + csv)\n",
    "        \n",
    "    df1 = df[df.isna().any(axis=1)]\n",
    "    if df.isnull().values.any():\n",
    "        ls_csv_with_na.append(csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ls_csv_with_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove csv with na value\n",
    "for csv in ['FTR.csv']:\n",
    "    os.remove(csv_dir + csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
